{"version":3,"file":"static/js/448.58d17a51.chunk.js","mappings":"6JASA,MAAMA,EAA4B,CAChCC,SAAU,SACVC,MAAO,eA8NF,MAAMC,EAAa,IA3NnB,MAGLC,WAAAA,CAAYC,GAA8B,KAFlCA,YAAM,EAGZC,KAAKD,OAAS,IAAKL,KAAmBK,EACxC,CAEA,uBAAME,CACJC,EACAC,EACAC,GAEAC,QAAQC,IAAI,+CAAgD,CAAEJ,QAAOC,aAAYC,UAGjF,MAAMG,GAAWC,EAAAA,EAAAA,MAGjB,GAFAH,QAAQC,IAAI,mCAAoCC,EAAW,CAAEZ,SAAUY,EAASZ,SAAUc,YAAaF,EAASG,QAAW,OAEtHH,IAAaA,EAASG,OACzB,MAAM,IAAIC,MAAM,yEAIlBX,KAAKD,OAAS,CACZJ,SAAUY,EAASZ,SACnBe,OAAQH,EAASG,OACjBd,MAAOW,EAASX,OAGlB,MAAMgB,EAASZ,KAAKa,aAAaX,EAAOC,EAAYC,GACpDC,QAAQC,IAAI,iCAAkCM,GAE9C,IAEE,IAAIE,EAEJ,OAHAT,QAAQC,IAAI,+BAAgCN,KAAKD,OAAOJ,UAGhDK,KAAKD,OAAOJ,UAClB,IAAK,SACHmB,QAAed,KAAKe,mBAAmBH,GACvC,MACF,IAAK,SACHE,QAAed,KAAKgB,mBAAmBJ,GACvC,MACF,QACE,MAAM,IAAID,MAAM,yBAAyBX,KAAKD,OAAOJ,YAIzD,OADAU,QAAQC,IAAI,iDAAkDQ,EAAOG,QAC9DH,CACT,CAAE,MAAOI,GAEP,GADAb,QAAQa,MAAM,2CAA4CA,GACtDA,aAAiBP,MACnB,MAAMO,EAER,MAAM,IAAIP,MAAM,kDAClB,CACF,CAEQE,YAAAA,CAAaX,EAAeC,EAAoBC,GACtD,MAMMe,EANoB,CACxB,KAAQ,WACR,OAAU,eACV,KAAQ,YAGgChB,IAAiDA,EAE3F,MAAO,YAAYC,2CAA+CF,SAAaiB,2OAM1CA,iXASMjB,sLAQtCA,kBACKiB,2BACSf,GACrB,CAEA,wBAAcW,CAAmBH,GAAsC,IAADQ,EAAAC,EACpEhB,QAAQC,IAAI,kCACZ,MAAMI,EAASV,KAAKD,OAAOW,OAE3B,IAAKA,EACH,MAAM,IAAIC,MAAM,iEAGlBN,QAAQC,IAAI,iCACZ,MAAMgB,QAAiBC,MAAM,6CAA8C,CACzEC,OAAQ,OACRC,QAAS,CACP,eAAgB,mBAChB,cAAiB,UAAUf,KAE7BgB,KAAMC,KAAKC,UAAU,CACnBhC,MAAOI,KAAKD,OAAOH,OAAS,gBAC5BiC,SAAU,CACR,CACEC,KAAM,SACNC,QAAS,iHAEX,CACED,KAAM,OACNC,QAASnB,IAGboB,YAAa,GACbC,WAAY,QAMhB,GAFA5B,QAAQC,IAAI,2BAA4BgB,EAASY,SAE5CZ,EAASa,GAAI,CAAC,IAADC,EAChB,MAAMlB,QAAcI,EAASe,OAE7B,MADAhC,QAAQa,MAAM,8BAA+BA,GACvC,IAAIP,MAAM,sBAAgC,QAAXyB,EAAAlB,EAAMA,aAAK,IAAAkB,OAAA,EAAXA,EAAaE,UAAW,kBAC/D,CAEA,MAAMC,QAAajB,EAASe,OAC5BhC,QAAQC,IAAI,kCACZ,MAAMyB,EAAyB,QAAlBX,EAAGmB,EAAKC,QAAQ,UAAE,IAAApB,GAAS,QAATC,EAAfD,EAAiBkB,eAAO,IAAAjB,OAAT,EAAfA,EAA0BU,QAG1C,OAFA1B,QAAQC,IAAI,8BAAqC,OAAPyB,QAAO,IAAPA,OAAO,EAAPA,EAASU,UAAU,EAAG,MAAO,OAEhEzC,KAAK0C,eAAeX,EAC7B,CAEA,wBAAcf,CAAmBJ,GAAsC,IAAD+B,EACpE,MAAMjC,EAASV,KAAKD,OAAOW,OAE3B,IAAKA,EACH,MAAM,IAAIC,MAAM,iEAGlB,MAAMW,QAAiBC,MAAM,wCAAyC,CACpEC,OAAQ,OACRC,QAAS,CACP,eAAgB,mBAChB,YAAaf,EACb,oBAAqB,cAEvBgB,KAAMC,KAAKC,UAAU,CACnBhC,MAAOI,KAAKD,OAAOH,OAAS,2BAC5BqC,WAAY,IACZJ,SAAU,CACR,CACEC,KAAM,OACNC,QAASnB,QAMjB,IAAKU,EAASa,GAAI,CAAC,IAADS,EAChB,MAAM1B,QAAcI,EAASe,OAC7B,MAAM,IAAI1B,MAAM,yBAAmC,QAAXiC,EAAA1B,EAAMA,aAAK,IAAA0B,OAAA,EAAXA,EAAaN,UAAW,kBAClE,CAEA,MACMP,EAAyB,QAAlBY,SADMrB,EAASe,QACPN,QAAQ,UAAE,IAAAY,OAAA,EAAfA,EAAiBE,KAEjC,OAAO7C,KAAK0C,eAAeX,EAC7B,CAGQW,cAAAA,CAAeX,GACrB,IAEE,MAAMe,EAAYf,EAAQgB,MAAM,eAChC,IAAKD,EACH,MAAM,IAAInC,MAAM,mCAGlB,MAAMqC,EAAYrB,KAAKsB,MAAMH,EAAU,IAEvC,IAAKI,MAAMC,QAAQH,GACjB,MAAM,IAAIrC,MAAM,4BAIlB,OAAOqC,EAAUI,IAAI,CAACC,EAAGC,KACvB,IAAKD,EAAEE,WAAaL,MAAMC,QAAQE,EAAEG,UAAiC,IAArBH,EAAEG,QAAQvC,QAAqC,kBAAdoC,EAAEI,QACjF,MAAM,IAAI9C,MAAM,oCAAoC2C,KAGtD,GAAID,EAAEI,QAAU,GAAKJ,EAAEI,QAAU,EAC/B,MAAM,IAAI9C,MAAM,4CAA4C2C,KAG9D,MAAO,CACLC,SAAUF,EAAEE,SACZC,QAASH,EAAEG,QACXC,QAASJ,EAAEI,UAGjB,CAAE,MAAOvC,GAEP,MADAb,QAAQa,MAAM,gCAAiCa,GACzC,IAAIpB,MAAM,yDAClB,CACF,GClOW+C,EAA2BC,MACtCzD,EACAC,EACAC,KAEAC,QAAQC,IAAI,4DAA6DJ,EAAO,cAAeC,EAAY,SAAUC,SACxGP,EAAWI,kBAAkBC,EAAOC,EAA0CC,G","sources":["services/llmService.ts","utils/questionBank.ts"],"sourcesContent":["import { Question } from '../App';\nimport { getSettings, LLMSettings } from '../utils/settings';\n\nexport interface LLMConfig {\n  apiKey?: string;\n  provider: 'openai' | 'claude';\n  model?: string;\n}\n\nconst DEFAULT_CONFIG: LLMConfig = {\n  provider: 'openai',\n  model: 'gpt-4o-mini'\n};\n\nexport class LLMService {\n  private config: LLMConfig;\n\n  constructor(config?: Partial<LLMConfig>) {\n    this.config = { ...DEFAULT_CONFIG, ...config };\n  }\n\n  async generateQuestions(\n    topic: string, \n    difficulty: 'easy' | 'medium' | 'hard', \n    count: number\n  ): Promise<Question[]> {\n    console.log('LLM Service: Starting question generation...', { topic, difficulty, count });\n    \n    // Get current settings from localStorage\n    const settings = getSettings();\n    console.log('LLM Service: Retrieved settings:', settings ? { provider: settings.provider, hasApiKey: !!settings.apiKey } : null);\n    \n    if (!settings || !settings.apiKey) {\n      throw new Error('No API configuration found. Please configure your API settings first.');\n    }\n\n    // Update config with current settings\n    this.config = {\n      provider: settings.provider,\n      apiKey: settings.apiKey,\n      model: settings.model\n    };\n\n    const prompt = this.createPrompt(topic, difficulty, count);\n    console.log('LLM Service: Generated prompt:', prompt);\n    \n    try {\n      console.log('LLM Service: Using provider:', this.config.provider);\n      let result: Question[];\n      \n      switch (this.config.provider) {\n        case 'openai':\n          result = await this.generateWithOpenAI(prompt);\n          break;\n        case 'claude':\n          result = await this.generateWithClaude(prompt);\n          break;\n        default:\n          throw new Error(`Unsupported provider: ${this.config.provider}`);\n      }\n      \n      console.log('LLM Service: Successfully generated questions:', result.length);\n      return result;\n    } catch (error) {\n      console.error('LLM Service: Error generating questions:', error);\n      if (error instanceof Error) {\n        throw error;\n      }\n      throw new Error('Failed to generate questions. Please try again.');\n    }\n  }\n\n  private createPrompt(topic: string, difficulty: string, count: number): string {\n    const difficultyMapping = {\n      'easy': 'beginner',\n      'medium': 'intermediate', \n      'hard': 'advanced'\n    };\n    \n    const difficultyLabel = difficultyMapping[difficulty as keyof typeof difficultyMapping] || difficulty;\n    \n    return `Generate ${count} multiple choice quiz questions about \"${topic}\" at ${difficultyLabel} difficulty level.\n\nRequirements:\n- Each question should have exactly 4 options (A, B, C, D)\n- Only one option should be correct\n- Questions should be educational and factually accurate\n- Difficulty should be appropriate for ${difficultyLabel} level learners\n- Avoid ambiguous or trick questions\n- For beginner level: focus on basic concepts and definitions\n- For intermediate level: include practical applications and connections\n- For advanced level: cover complex scenarios and edge cases\n\nPlease respond with a JSON array in this exact format:\n[\n  {\n    \"question\": \"What is the main concept of ${topic}?\",\n    \"options\": [\"Option A\", \"Option B\", \"Option C\", \"Option D\"],\n    \"correct\": 0\n  }\n]\n\nThe \"correct\" field should be the index (0-3) of the correct answer.\n\nTopic: ${topic}\nDifficulty: ${difficultyLabel}\nNumber of questions: ${count}`;\n  }\n\n  private async generateWithOpenAI(prompt: string): Promise<Question[]> {\n    console.log('OpenAI: Starting generation...');\n    const apiKey = this.config.apiKey;\n    \n    if (!apiKey) {\n      throw new Error('OpenAI API key not found. Please configure your API settings.');\n    }\n\n    console.log('OpenAI: Making API request...');\n    const response = await fetch('https://api.openai.com/v1/chat/completions', {\n      method: 'POST',\n      headers: {\n        'Content-Type': 'application/json',\n        'Authorization': `Bearer ${apiKey}`\n      },\n      body: JSON.stringify({\n        model: this.config.model || 'gpt-3.5-turbo',\n        messages: [\n          {\n            role: 'system',\n            content: 'You are a helpful assistant that generates educational quiz questions. Always respond with valid JSON format.'\n          },\n          {\n            role: 'user',\n            content: prompt\n          }\n        ],\n        temperature: 0.7,\n        max_tokens: 2000\n      })\n    });\n\n    console.log('OpenAI: Response status:', response.status);\n    \n    if (!response.ok) {\n      const error = await response.json();\n      console.error('OpenAI: API error response:', error);\n      throw new Error(`OpenAI API error: ${error.error?.message || 'Unknown error'}`);\n    }\n\n    const data = await response.json();\n    console.log('OpenAI: Received response data');\n    const content = data.choices[0]?.message?.content;\n    console.log('OpenAI: Extracted content:', content?.substring(0, 200) + '...');\n    \n    return this.parseQuestions(content);\n  }\n\n  private async generateWithClaude(prompt: string): Promise<Question[]> {\n    const apiKey = this.config.apiKey;\n    \n    if (!apiKey) {\n      throw new Error('Claude API key not found. Please configure your API settings.');\n    }\n\n    const response = await fetch('https://api.anthropic.com/v1/messages', {\n      method: 'POST',\n      headers: {\n        'Content-Type': 'application/json',\n        'x-api-key': apiKey,\n        'anthropic-version': '2023-06-01'\n      },\n      body: JSON.stringify({\n        model: this.config.model || 'claude-3-sonnet-20240229',\n        max_tokens: 2000,\n        messages: [\n          {\n            role: 'user',\n            content: prompt\n          }\n        ]\n      })\n    });\n\n    if (!response.ok) {\n      const error = await response.json();\n      throw new Error(`Anthropic API error: ${error.error?.message || 'Unknown error'}`);\n    }\n\n    const data = await response.json();\n    const content = data.content[0]?.text;\n    \n    return this.parseQuestions(content);\n  }\n\n\n  private parseQuestions(content: string): Question[] {\n    try {\n      // Extract JSON from the response (in case there's extra text)\n      const jsonMatch = content.match(/\\[[\\s\\S]*\\]/);\n      if (!jsonMatch) {\n        throw new Error('No JSON array found in response');\n      }\n\n      const questions = JSON.parse(jsonMatch[0]);\n      \n      if (!Array.isArray(questions)) {\n        throw new Error('Response is not an array');\n      }\n\n      // Validate each question\n      return questions.map((q, index) => {\n        if (!q.question || !Array.isArray(q.options) || q.options.length !== 4 || typeof q.correct !== 'number') {\n          throw new Error(`Invalid question format at index ${index}`);\n        }\n        \n        if (q.correct < 0 || q.correct > 3) {\n          throw new Error(`Invalid correct answer index at question ${index}`);\n        }\n\n        return {\n          question: q.question,\n          options: q.options,\n          correct: q.correct\n        };\n      });\n    } catch (error) {\n      console.error('Failed to parse LLM response:', content);\n      throw new Error('Failed to parse generated questions. Please try again.');\n    }\n  }\n}\n\n// Singleton instance\nexport const llmService = new LLMService();","import { Question } from '../App';\nimport { llmService } from '../services/llmService';\n\nexport const generateQuestionsWithLLM = async (\n  topic: string, \n  difficulty: string, \n  count: number\n): Promise<Question[]> => {\n  console.log('QuestionBank: generateQuestionsWithLLM called with topic:', topic, 'difficulty:', difficulty, 'count:', count);\n  return await llmService.generateQuestions(topic, difficulty as 'easy' | 'medium' | 'hard', count);\n};"],"names":["DEFAULT_CONFIG","provider","model","llmService","constructor","config","this","generateQuestions","topic","difficulty","count","console","log","settings","getSettings","hasApiKey","apiKey","Error","prompt","createPrompt","result","generateWithOpenAI","generateWithClaude","length","error","difficultyLabel","_data$choices$","_data$choices$$messag","response","fetch","method","headers","body","JSON","stringify","messages","role","content","temperature","max_tokens","status","ok","_error$error","json","message","data","choices","substring","parseQuestions","_data$content$","_error$error2","text","jsonMatch","match","questions","parse","Array","isArray","map","q","index","question","options","correct","generateQuestionsWithLLM","async"],"sourceRoot":""}